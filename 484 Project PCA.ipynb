{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"13_xW8ypio0KfBXBtd5oUWKSmMqjQs4lI","timestamp":1681962273187}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Below here is working on PCA and Lasso"],"metadata":{"id":"NTKxLZp-FaNc"}},{"cell_type":"code","source":["%matplotlib inline\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd '/content/gdrive/My Drive/Econ 484/project'"],"metadata":{"id":"2kCf0Qy_t73O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681962471782,"user_tz":360,"elapsed":152855,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}},"outputId":"ef615eae-42b7-4c9f-879d-e7ee84dec1da"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Econ 484/project\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6dvt_zSm-BtE","executionInfo":{"status":"ok","timestamp":1681962473541,"user_tz":360,"elapsed":1766,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}}},"outputs":[],"source":["from sklearn import preprocessing as pp\n","from pandas import DataFrame\n","\n","def PolynomialFeatures_labeled(input_df,power):\n","    '''Basically this is a cover for the sklearn preprocessing function. \n","    The problem with that function is if you give it a labeled dataframe, it ouputs an unlabeled dataframe with potentially\n","    a whole bunch of unlabeled columns. \n","    Inputs:\n","    input_df = Your labeled pandas dataframe (list of x's not raised to any power) \n","    power = what order polynomial you want variables up to. (use the same power as you want entered into pp.PolynomialFeatures(power) directly)\n","    Ouput:\n","    Output: This function relies on the powers_ matrix which is one of the preprocessing function's outputs to create logical labels and \n","    outputs a labeled pandas dataframe   \n","    '''\n","    poly = pp.PolynomialFeatures(power, include_bias = False)\n","    output_nparray = poly.fit_transform(input_df)\n","    powers_nparray = poly.powers_\n","\n","    input_feature_names = list(input_df.columns)\n","    target_feature_names = [\"Constant Term\"]\n","    for feature_distillation in powers_nparray[1:]:\n","        intermediary_label = \"\"\n","        final_label = \"\"\n","        for i in range(len(input_feature_names)):\n","            if feature_distillation[i] == 0:\n","                continue\n","            else:\n","                variable = input_feature_names[i]\n","                power = feature_distillation[i]\n","                intermediary_label = \"%s^%d\" % (variable,power)\n","                if final_label == \"\":         #If the final label isn't yet specified\n","                    final_label = intermediary_label\n","                else:\n","                    final_label = final_label + \" x \" + intermediary_label\n","        target_feature_names.append(final_label)\n","    output_df = pd.DataFrame(output_nparray, columns = target_feature_names)\n","    return output_df"]},{"cell_type":"code","execution_count":3,"source":["#Import the correct packages \n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","import statsmodels.api as sm\n","import pandas as pd\n","from sklearn.linear_model import LassoCV\n","import numpy as np\n","\n","\n","#Data cleaning from Hannah's code\n","shooter = pd.read_csv('Firearms_cleaned_Apr7.csv')\n","shooter = shooter.drop(['Unnamed: 0'], axis = 1)\n","casualties = pd.read_csv('numInj_with_index_Apr7.csv', index_col = 'Unnamed: 0')\n","casualties = casualties.drop(['Case #'], axis = 1)\n","casualties.rename(columns={'0': 'Casualties'}, inplace=True)\n","\n","# Turn the caliber and classification categorical variables into dummy variables\n","shooter = pd.get_dummies(shooter, prefix = ['Caliber', 'Classification'], columns = ['Caliber', 'Classification'])\n","\n","# First, we create three new dataframes with our variables of interest. \n","class1 = pd.DataFrame(shooter.loc[:, 'Classification_1.0'])\n","class2 = pd.DataFrame(shooter.loc[:, 'Classification_2.0'])\n","class3 = pd.DataFrame(shooter.loc[:, 'Classification_3.0'])\n","\n","# Next, we drop all of the classification variables from our dataframe - everything will be in reference to handguns which is Classification 0.\n","data = shooter.drop(['Classification_0.0', 'Classification_1.0', 'Classification_2.0', 'Classification_3.0'], axis = 1)"],"outputs":[],"metadata":{"id":"Oy-_OxxqxU5l","executionInfo":{"status":"ok","timestamp":1681962474964,"user_tz":360,"elapsed":1427,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}}}},{"cell_type":"code","source":["#data = PolynomialFeatures_labeled(data, 2)"],"metadata":{"id":"p_Gu60ANfzSs","executionInfo":{"status":"ok","timestamp":1681962474966,"user_tz":360,"elapsed":7,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"source":["#Make train/test split on all the datasets so they match up\n","train, test, casualTrain, casualTest, class1Train, class1Test, class2Train, class2Test, class3Train, class3Test = train_test_split(data, casualties, class1, class2, class3, random_state = 0)\n","print(train.shape,test.shape)\n","\n","#Standardize before doing PCA\n","scaler = StandardScaler()\n","trainScaled = scaler.fit_transform(train)\n","testScaled = scaler.transform(test)\n","\n","pca = PCA(n_components=3)\n","pcaDataTrain = pca.fit_transform(trainScaled)\n","\n","print(pcaDataTrain.shape)\n","\n","#Transform the test set\n","pcaDataTest = pca.transform(testScaled)\n","print(pcaDataTest.shape)\n","\n","#Now we only have the principle components to run on Lasso 2SLS"],"outputs":[{"output_type":"stream","name":"stdout","text":["(141, 422) (47, 422)\n","(141, 3)\n","(47, 3)\n"]}],"metadata":{"id":"ezrdBPvr62Ag","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681962475520,"user_tz":360,"elapsed":560,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}},"outputId":"fa7290f9-aecb-4cf6-cfaa-3184bee1e651"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"U5vOCvyNIur6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681962475520,"user_tz":360,"elapsed":14,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}},"outputId":"dfa56a56-6032-4709-84ab-e624a64761da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Lasso score on training set: 0.0150\n","Lasso score on test set: -0.0697\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:1568: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["# Run Lasso on a random training set and test set to check the score so that we can compare it to the score we'd get on ridge.\n","lassocv = LassoCV(cv = 5, max_iter=100000).fit(pcaDataTrain, casualTrain)\n","print('Lasso score on training set: {:.4f}'.format(lassocv.score(pcaDataTrain, casualTrain)))\n","print('Lasso score on test set: {:.4f}'.format(lassocv.score(pcaDataTest, casualTest)))\n","\n","# do lasso on a randomly chosen training set and lasso.score to the test set, preliminary step what method we chose and how we chose them. test"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ecHA1TcTXzbv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681962475521,"user_tz":360,"elapsed":12,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}},"outputId":"e6db2843-30c1-44b8-eb7f-77343e5f8d34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Selected alpha value: 30.4721\n"]}],"source":["alpha = lassocv.alpha_\n","\n","# Print selected alpha value\n","print(\"Selected alpha value: {:.4f}\".format(alpha))"]},{"cell_type":"markdown","source":["If it had worked, this is what we would have done. Unfortunately, it did not."],"metadata":{"id":"tsTv2hn0uTxv"}},{"cell_type":"code","execution_count":8,"source":["#Run Lasso on all of the models\n","lassoy1 = LassoCV(max_iter=1000).fit(pcaDataTrain, casualTrain)\n","\n","lassod1 = LassoCV(max_iter=1000).fit(pcaDataTrain, class1Train)\n","lassod2 = LassoCV(max_iter=1000).fit(pcaDataTrain, class2Train)\n","lassod3 = LassoCV(max_iter=1000).fit(pcaDataTrain, class3Train)\n","\n","#These seem relatively reasonable\n","lassoy1.alpha_,lassod1.alpha_,lassod2.alpha_,lassod3.alpha_"],"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:1568: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:1568: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:1568: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:1568: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"execute_result","data":{"text/plain":["(30.47213259004944,\n"," 0.04662503362812325,\n"," 0.00014581871868651514,\n"," 0.004223342318581071)"]},"metadata":{},"execution_count":8}],"metadata":{"id":"cZPx_r8lB629","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681962475667,"user_tz":360,"elapsed":155,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}},"outputId":"93f55429-c916-4c08-a353-99a0e19be53d"}},{"cell_type":"code","execution_count":9,"source":["#Print coefficients from Lasso \n","lassod1.coef_,lassod2.coef_,lassod3.coef_"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([ 0.00000000e+00, -0.00000000e+00, -1.16982136e-18]),\n"," array([-0.00992772,  0.0051752 ,  0.01352656]),\n"," array([ 0.04129261, -0.0071584 , -0.03649744]))"]},"metadata":{},"execution_count":9}],"metadata":{"id":"gAiNOMWTDYbC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681962475668,"user_tz":360,"elapsed":18,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}},"outputId":"551ad3c5-2655-4925-8bf1-51e5b5639bf8"}},{"cell_type":"code","execution_count":10,"source":["#Find which coefficients are nonzero\n","nonZero = (lassod1.coef_ != 0) + (lassod2.coef_ != 0) + (lassod3.coef_ != 0)\n","Xun = pcaDataTrain[:,nonZero]\n","\n","assert Xun.shape[1] == np.sum(nonZero)  #Make sure it is getting the right columns"],"outputs":[],"metadata":{"id":"9ccXgGjTEV-0","executionInfo":{"status":"ok","timestamp":1681962475668,"user_tz":360,"elapsed":14,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}}}},{"cell_type":"code","execution_count":11,"source":["#Add constant and run regression\n","Xun = sm.add_constant(Xun)\n","\n","rhs = np.hstack([class1Train,class2Train,class3Train,Xun])\n","model = sm.OLS(casualTrain,rhs)\n","res = model.fit()\n","\n","print(res.summary())\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:             Casualties   R-squared:                       0.050\n","Model:                            OLS   Adj. R-squared:                  0.007\n","Method:                 Least Squares   F-statistic:                     1.170\n","Date:                Thu, 20 Apr 2023   Prob (F-statistic):              0.326\n","Time:                        03:47:55   Log-Likelihood:                -810.38\n","No. Observations:                 141   AIC:                             1635.\n","Df Residuals:                     134   BIC:                             1655.\n","Df Model:                           6                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","x1            -5.4468     22.201     -0.245      0.807     -49.356      38.463\n","x2             2.4647     19.048      0.129      0.897     -35.208      40.138\n","x3            20.6465     17.483      1.181      0.240     -13.931      55.224\n","const         14.6734     10.316      1.422      0.157      -5.730      35.077\n","x4             2.6347      1.927      1.367      0.174      -1.177       6.446\n","x5            -1.1959      1.953     -0.612      0.541      -5.059       2.667\n","x6            -1.2514      2.099     -0.596      0.552      -5.403       2.900\n","==============================================================================\n","Omnibus:                      294.537   Durbin-Watson:                   1.985\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):            90907.189\n","Skew:                          10.866   Prob(JB):                         0.00\n","Kurtosis:                     125.480   Cond. No.                         14.7\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"]}],"metadata":{"id":"9djyj6Y2DzyX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681962475669,"user_tz":360,"elapsed":14,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}},"outputId":"8fcdeb18-3b60-4fb3-90e4-dd981864f297"}},{"cell_type":"markdown","source":["### Note that x1, x2, x3 are the classifications of guns and then x4-x10 are the pca components that were selected by lasso"],"metadata":{"id":"BtVDeObvFs3g"}},{"cell_type":"markdown","source":["## Same thing as above but using lasso on entire dataset"],"metadata":{"id":"Iof-FGkEHK_a"}},{"cell_type":"code","execution_count":12,"source":["from sklearn.linear_model import LassoCV\n","\n","fullScaled = scaler.transform(data)\n","pcaDataFull = pca.transform(fullScaled)\n","\n","#Run Lasso on all of the models\n","lassoy1 = LassoCV(max_iter=1000).fit(pcaDataFull, casualties)\n","\n","lassod1 = LassoCV(max_iter=1000).fit(pcaDataFull, class1)\n","lassod2 = LassoCV(max_iter=1000).fit(pcaDataFull, class2)\n","lassod3 = LassoCV(max_iter=1000).fit(pcaDataFull, class3)\n","\n","\n","#Find which coefficients are nonzero\n","nonZero = (lassod1.coef_ != 0) + (lassod2.coef_ != 0) + (lassod3.coef_ != 0)\n","Xun = pcaDataTrain[:,nonZero]\n","\n","assert Xun.shape[1] == np.sum(nonZero)  #Make sure it is getting the right columns\n","\n","#Add constant and run regression\n","Xun = sm.add_constant(Xun)\n","\n","rhs = np.hstack([class1Train,class2Train,class3Train,Xun])\n","model = sm.OLS(casualTrain,rhs)\n","res = model.fit()\n","\n","print(res.summary())\n"],"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:1568: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:1568: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:             Casualties   R-squared:                       0.050\n","Model:                            OLS   Adj. R-squared:                  0.007\n","Method:                 Least Squares   F-statistic:                     1.170\n","Date:                Thu, 20 Apr 2023   Prob (F-statistic):              0.326\n","Time:                        03:47:55   Log-Likelihood:                -810.38\n","No. Observations:                 141   AIC:                             1635.\n","Df Residuals:                     134   BIC:                             1655.\n","Df Model:                           6                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","x1            -5.4468     22.201     -0.245      0.807     -49.356      38.463\n","x2             2.4647     19.048      0.129      0.897     -35.208      40.138\n","x3            20.6465     17.483      1.181      0.240     -13.931      55.224\n","const         14.6734     10.316      1.422      0.157      -5.730      35.077\n","x4             2.6347      1.927      1.367      0.174      -1.177       6.446\n","x5            -1.1959      1.953     -0.612      0.541      -5.059       2.667\n","x6            -1.2514      2.099     -0.596      0.552      -5.403       2.900\n","==============================================================================\n","Omnibus:                      294.537   Durbin-Watson:                   1.985\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):            90907.189\n","Skew:                          10.866   Prob(JB):                         0.00\n","Kurtosis:                     125.480   Cond. No.                         14.7\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:1568: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:1568: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"metadata":{"id":"woTS_bDOD3PA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681962475670,"user_tz":360,"elapsed":13,"user":{"displayName":"Hannah Hammond","userId":"15135244055666564464"}},"outputId":"ee60f677-6ee2-4119-ac26-6c989f6e4712"}}]}